---
title: Memory Subsystem & Performance Optimization
date: 2026-01-05 17:43:31
tags: [cs,os]
---

## 1. 存储器的“速度鸿沟”

理解性能瓶颈的关键在于理解延迟 (Latency)：

- **L1 Cache:** ~1 ns (光速)

- **L2 Cache:** ~3-4 ns

- **L3 Cache:** ~10-20 ns

- Main Memory (RAM): ~100 ns (巨大的鸿沟)

  结论： CPU 大部分时间并不在计算，而是在等待数据从内存搬运过来。优化的核心是 减少 Cache Miss。

- ![](https://raw.githubusercontent.com/Ze-d/blog-img/main/licensed-image.jpg)

## 2. 缓存行 (Cache Line) 机制

- **规格：** 主流 CPU 为 **64 字节**。
- **目的：** 利用**空间局部性 (Spatial Locality)**。读取一个 `int` (4字节)，顺便把后面 60 字节也加载进来，因为程序往往会接着访问相邻数据。
- **双刃剑：**
  - **红利：** 顺序访问数组极快。
  - **灾难：** 伪共享 (False Sharing)。

## 3. 伪共享 (False Sharing)

- **现象：** 两个毫无逻辑关系的变量 `A` 和 `B`，恰好位于同一个 64 字节的缓存行中。
- **过程：**
  1. Core 1 修改 `A` -> 导致整个缓存行标记为 Invalid。
  2. Core 2 只是想读 `B` -> 发现缓存行失效 -> 强制去内存重读。
- **性能影响：** 多核之间像打乒乓球一样争夺同一个缓存行的所有权，导致性能下降数倍。
- **解决方案：** **缓存行填充 (Padding)**。
  - **Java:** `@Contended` 注解。
  - **C++:** `alignas(64)`。
  - **原理：** 强制将变量隔离在不同的缓存行，保持“社交距离”。

## 4. 硬件预取器 (Hardware Prefetcher)

- **定义：** CPU 内部试图预测数据访问模式并提前拉取数据的单元。
- **有效场景：** **连续内存访问** (Sequential / Stride)。
- **无效场景：** **指针追逐 (Pointer Chasing)**。即访问地址跳跃、无规律（如链表、树、图）。

## 5. 语言级对比：Java vs. C++

这是高性能场景下选型的关键依据。

| **特性**       | **C++ (STL Vector / Array)**               | **Java (ArrayList / Object[])**                            |
| -------------- | ------------------------------------------ | ---------------------------------------------------------- |
| **内存布局**   | **Flat (扁平连续)**                        | **Reference (引用跳转)**                                   |
| **数据存储**   | 对象数据直接紧挨着存储。                   | 数组存的是**指针**，对象分散在堆的各个角落。               |
| **缓存友好度** | **极高**。加载一行缓存行包含多个完整对象。 | **极低**。加载一行缓存行可能只包含一堆指针，需要二次寻址。 |
| **预取器效果** | 完美触发。                                 | 经常失效，CPU 只能串行等待内存。                           |
| **对象头开销** | 无 (Zero Overhead)。                       | 每个对象额外 12-16 字节头信息，降低有效数据密度。          |

